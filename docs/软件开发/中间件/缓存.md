# 缓存

## 缓存的用途

- 高性能

当一个数据获取的请求查询数据库比较耗时（假设是`600ms`），并且查询出来的结果在接下来的几个小时内都不会变化，这时可以将查询的结果放在缓存里，当下次相同的请求发起时，直接从缓存中读取数据，耗时在`2ms`，性能提升300倍。像这种需要复杂操作耗时查出来的结果并且变化不大，但是有很多读请求，直接将查询结果放在缓存中，后续的查询直接查询缓存即可。

- 高并发

MySQL数据库单机大概能支撑`2000QPS`，当系统高峰期的并发量过高时，MySQL单机数据库肯定会挂掉。这时如果将数据放在缓存里，就可以支撑并发量到几万或者几十万。单机承载并发量是MySQL的几十倍。

**缓存是在内存中的，内存天然就支持高并发。**

## 3种常用的缓存读写策略

### Cache Aside Pattern（旁路缓存模式）

`Cache Aside Pattern`是我们平时使用比较多的一种缓存读写模式，比较适合读请求比较多的场景。

`Cache Aside Pattern`中服务端需要同时维系`db`和`cache`，并且是以db的结果为准。

这个模式下的缓存读写步骤如下。

- 写：
  - 先更新`db`
  - 然后直接删除`cache`

  ![CacheAsidePattern写数据](./缓存/CacheAsidePattern写数据.webp)

- 读：
  - 从`cache`中读取数据，读取到就直接返回
  - `cache`中读取不到的话，就从`db`中读取数据返回
  - 再把数据放到`cache`中
  ![CacheAsidePattern读数据](./缓存/CacheAsidePattern读数据.webp)

- 场景一：在写数据的过程中，可以先删除cache，后更新db吗？

肯定是不行的，因为这样可能会造成**数据库（db）和缓存（cache）数据不一致**的问题。

举例：请求1先写数据A，请求2随后读数据A的话，就很有可能产生数据不一致的问题。

这个过程可以简单描述为：

> 请求1先把cache中的A数据删除 -> 请求2从db中读取数据 -> 请求1再把db中的A数据更新

- 场景二：在写数据的过程中，先更新db，后删除cache就没有问题了吗？

理论上来说还是可能会出现数据不一致的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多的。

举例：请求1先读数据A，请求2随后写数据A，并且数据A在请求1请求之前不在缓存中的话，也可能产生数据不一致的问题。

这个过程可以简单描述为：

> 请求1从db读数据A -> 请求2更新db中的数据A（此时缓存中无数据A，故不用执行删除缓存的操作）-> 请求1将数据A写入cache

- 缺陷

1. 首次请求数据一定不在cache的问题

    解决办法：可以将热点数据提前放入`cache`中。

2. 写操作比较频繁的话导致`cache`中的数据会频繁被删除，这样会影响缓存命中率

    解决办法：
      - 数据库和缓存数据强一致场景：更新db的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
      - 可以短暂地允许数据库和缓存数据不一致的场景：更新db的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

### Read/Write Through Pattern（读写穿透）

`Read/Write Through Pattern`中服务端把`cache`视为主要的数据存储，从中读取数据并将数据写入其中。`cache`服务负责将此数据读取和写入`db`，从而减轻了应用程序的职责。

这种缓存读写策略在平时开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存`Redis`并没有提供`cache`将数据写入`db`的功能。

- 写（Write Through）：
  - 先查`cache`，`cache`中不存在，直接更新`db`
  - `cache`中存在，则先更新`cache`，然后`cache`服务自己更新`db`（同步更新`cache`和`db`）
  ![WriteThroughPattern](./缓存/WriteThroughPattern.webp)

- 读（Read Through）：
  - 从`cache`中读取数据，读取到就直接返回
  - 读取不到的话，先从`db`加载，写入到`cache`后返回响应
  ![ReadThroughPattern](./缓存/ReadThroughPattern.webp)

`Read/Write Through Pattern`实际上只是在`Cache Aside Pattern`之上进行了封装。在`Cache Aside Pattern`下，发生读请求的时候，如果`cache`中不存在对应的数据，是由客户端自己负责把数据写入`cache`，而`Read/Write Through Pattern`则是`cache`服务自己来写入缓存的，这对客户端是透明的。

和`Cache Aside Pattern`一样，`Read/Write Through Pattern`也有首次请求数据一定不再`cache`的问题，对于热点数据可以提前放入缓存中。

### Write Behind Pattern（异步缓存写入）

`Write Behind Pattern`和`Read/Write Through Pattern`很相似，两者都是由`cache`服务来负责`cache`和`db`的读写。

但是，两个又有很大的不同：`Read/Write Through Pattern`是同步更新`cache`和`db`，而`Write Behind Pattern`则是只更新缓存，不直接更新`db`，而是改为异步批量的方式来更新`db`。

很明显，这种方式对数据一致性带来了更大的挑战，比如`cache`数据可能还没异步更新`db`的话，`cache`服务可能就挂掉了。

这种策略在我们平时开发过程中也非常非常少见，但不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL的`Innodb Buffer Pool`机制都用了这种策略。

`Write Behind Pattern`下`db`的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

## Redis
### Redis的特性

1. 支持复杂的数据结构

Redis拥有多种数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，Redis会是不错的选择。

2. 原生支持集群模式

在Redis 3.x版本中，就能支持`cluster`模式。

3. 性能

由于Redis只使用单核，在每一个核上存储小于`100k`的小数据时，性能较高。

### Redis的线程模型

Redis内部使用文件事件处理器`file event handler`，这个文件事件处理器是单线程的，所以Redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，将产生事件的socket压入内存队列中，事件分派器根据socket上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含4个部分：

- 多个socket
- IO多路复用工具
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个socket可能会并发产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，会将产生事件的socket放入队列中排队，事件分派器每次从队列中取出一个socket，根据socket的事件类型交给对应的事件处理器进行处理。

来看客户端与Redis的一次通信过程：
![image.png](https://cdn.nlark.com/yuque/0/2023/png/763022/1674364927062-94e79aaf-78a7-40b4-ba16-eb399e533283.png#averageHue=%236d6d6d&clientId=u92ae7ee9-f065-4&from=paste&id=u3e17950c&originHeight=534&originWidth=924&originalType=url&ratio=1&rotation=0&showTitle=false&size=83073&status=done&style=none&taskId=ud323b27e-00ef-4164-a991-3621e5d912e&title=)

通信是通过socket来完成的。

首先，Redis服务端进程初始化的时候，会将server socket的`AE_READABLE`事件与连接应答处理器关联。

客户端socket01向Redis进程的server socket请求建立连接，此时server socket会产生一个`AE_READAblE`事件，IO多路复用程序监听到server socket产生的事件后，将该socket压入队列中。文件事件分派器从队列中获取socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的socket01，并将改socket01的`AE_READABLE`事件与命令请求处理器关联。

假设此时客户端发送了一个`set key value`请求，此时Redis中的socket01会产生`AE_READABLE`事件，IO多路复用程序将socket01压入队列，此时事件分派器从队列中获取到socket01产生的`AE_READABLE`事件，由于前面socket01的`AE_READABLE`事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取socket01的`key value`并在自己内存中完成`key value`的设置。操作完成后，它会将socket01的`AE_WRITABLE`事件与命令回复处理器关联。

如果此时客户端准备好接收返回结果了，那么Redis中的socket01会产生一个`AE_WRITABLE`事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对socket01输入本次操作的一个结果，比如ok，之后解除socket01的`AE_WRITABLE`事件与命令回复处理器的关联。
这样便完成了一次通信。

### Redis单线程模型效率高的原因

- 纯内存操作
- 核心是基于非阻塞的IO多路复用机制
- C语言实现，一般来说，C语言实现的程序“距离”操作系统更近，执行速度相对会更快
- 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题

### Redis 6.0开始引入多线程

**注意！** Redis 6.0之后的版本抛弃了单线程模型这一设计，原本使用单线程运行的Redis也开始选择性地使用多线程模型。

前面还在强调Redis单线程模型的高效性，现在为什么又要引入多线程？这其实说明Redis在有些方面，单线程已经不具备优势了。因为读写网络的Read/Write系统调用在Redis执行期间占用了大部分CPU时间，如果把对网络读写做成多线程的方式对性能会有很大提升。

**Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。** 之所以这么设计是不想Redis因为多线程而变得复杂，需要去控制key、lua、事务、LPUSH/LPOP等等的并发问题。

Reids选择使用单线程模型处理客户端的请求主要还是因为CPU不是Redis服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络I/O操作上；而Redis引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间（释放操作不会阻塞网络IO读写，因为网络IO读写与释放的命令执行不是同一个线程）也能减少对Redis主线程阻塞的时间，提高执行的效率。
